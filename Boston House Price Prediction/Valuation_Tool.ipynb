{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7eeb33",
   "metadata": {},
   "source": [
    "## Valuation Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f52796",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6002bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ebbbf",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00a9a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanemena/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston_dataset = load_boston()\n",
    "data=pd.DataFrame(data=boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e819e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  CHAS    NOX     RM     DIS  RAD    TAX  PTRATIO       B  \\\n",
       "0  0.00632  18.0   0.0  0.538  6.575  4.0900  1.0  296.0     15.3  396.90   \n",
       "1  0.02731   0.0   0.0  0.469  6.421  4.9671  2.0  242.0     17.8  396.90   \n",
       "2  0.02729   0.0   0.0  0.469  7.185  4.9671  2.0  242.0     17.8  392.83   \n",
       "3  0.03237   0.0   0.0  0.458  6.998  6.0622  3.0  222.0     18.7  394.63   \n",
       "4  0.06905   0.0   0.0  0.458  7.147  6.0622  3.0  222.0     18.7  396.90   \n",
       "\n",
       "   LSTAT  \n",
       "0   4.98  \n",
       "1   9.14  \n",
       "2   4.03  \n",
       "3   2.94  \n",
       "4   5.33  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=data.drop(['INDUS','AGE'],axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0ac4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to work with log values\n",
    "\n",
    "log_prices=np.log(boston_dataset.target)\n",
    "#log_prices.shape we need two dimmensions! --> transform to a dataframe\n",
    "target=pd.DataFrame(log_prices,columns=['PRICE'])\n",
    "target.shape #Now is two dimmensional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cde37",
   "metadata": {},
   "source": [
    "We're not going to be customizing all the values, because something like crime per capita is quite hard to know or the acres of industrial land in a particular area, it's also really hard to know. We're gonna make some assumptions.\n",
    "\n",
    "In other words, for the property that we're looking at, we're just gonna go with the average for all of Boston, for now at least..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c6d42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables to store row numbers for later use\n",
    "\n",
    "CRIM_IDX=0\n",
    "ZN_IDX=1\n",
    "CHAS_IDX=2\n",
    "RM_IDX=4\n",
    "PTRATIO_IDX=8\n",
    "\n",
    "#property_stats=np.ndarray(shape=(1,11)) #empty, now we add values\n",
    "#property_stats[0][CRIM_IDX]=features['CRIM'].mean()\n",
    "#property_stats[0][ZN_IDX]=features['ZN'].mean()\n",
    "#property_stats[0][CHAS_IDX]=features['CHAS'].mean()\n",
    "#property_stats[0][RM_IDX]=features['RM'].mean()\n",
    "#property_stats[0][PTRATIO_IDX]=features['PTRATIO'].mean()# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b76f5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87739231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features.mean().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99492e84",
   "metadata": {},
   "source": [
    "Calculate the mean value for all the features at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42fa9c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61352356e+00, 1.13636364e+01, 6.91699605e-02, 5.54695059e-01,\n",
       "        6.28463439e+00, 3.79504269e+00, 9.54940711e+00, 4.08237154e+02,\n",
       "        1.84555336e+01, 3.56674032e+02, 1.26530632e+01]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_stats=features.mean().values.reshape(1,11)\n",
    "property_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4ce07",
   "metadata": {},
   "source": [
    "We need to obtain the estimated theta values for our model and we can also compute the root mean square error for our prediction interval.\n",
    "\n",
    "The `fit` method needs two inputs: the features and our target. This calculates all the theta values in the background.\n",
    "To get the predicted values or the fitted values, we can use `regr.predict(features)`\n",
    "\n",
    "So based on our features dataframe we are calculating all the predicted values using the thetas from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "894b0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=LinearRegression().fit(features,target) # all thetas\n",
    "fitted_vals=regr.predict(features) # all us predictions\n",
    "\n",
    "#Calculate MSE and RMSE\n",
    "\n",
    "MSE = mean_squared_error(target,fitted_vals)\n",
    "RMSE = np.sqrt(MSE)\n",
    "#the unit are log dollar prices in 000s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c30f5b",
   "metadata": {},
   "source": [
    "Now..We'll create a Python function wich will estimate the log house prices for a specific property. \n",
    "\n",
    "We'll first get the log prices , the log estimate, using our data set and afterwards we'll do step 2 where we convert this ouput into today's dollar values.\n",
    "\n",
    "We'll add only four arguments to our function: `nr_rooms` `students_per_classroom`, `next_to_river` and `high_confidence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67e8ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_estimate(nr_rooms,\n",
    "                    students_per_classroom,\n",
    "                    next_to_river=False,\n",
    "                    high_confidence=True):\n",
    "    \n",
    "    #Configure property\n",
    "    property_stats[0][RM_IDX]=nr_rooms\n",
    "    property_stats[0][PTRATIO_IDX]=students_per_classroom\n",
    "    \n",
    "    if next_to_river:\n",
    "         property_stats[0][CHAS_IDX]=1\n",
    "    else:\n",
    "         property_stats[0][CHAS_IDX]=0\n",
    "    \n",
    "    #make prediction\n",
    "    log_estimate = regr.predict(property_stats)[0][0]\n",
    "    \n",
    "    #Calc Range\n",
    "    if high_confidence: #we calculate the 95%\n",
    "        upper_bound = log_estimate + 2*RMSE\n",
    "        lower_bound = log_estimate - 2*RMSE\n",
    "        interval = 95\n",
    "    else:    #we calculate 68% oly 1 standart desviation or one sigma\n",
    "        upper_bound = log_estimate + RMSE\n",
    "        lower_bound = log_estimate - RMSE\n",
    "        interval = 68\n",
    "        \n",
    "    return log_estimate, upper_bound, lower_bound, interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b182111",
   "metadata": {},
   "source": [
    "We must consider inflation to make our calculations considering that the values of the houses are in dollars at the price in 1970. So given that let's make an adjustment to the estimates that our model is spitting out. \n",
    "\n",
    "The only question is - how do we get a more realistic price out of our little valuation tool?\n",
    "To evaluate we first calculate the `median` of our `target` and then we compare it with the `median` of the values of the houses today on the *Zillow* sales page and finally we calculate a `scale-factor` for our model.\n",
    "https://www.zillow.com/boston-ma/home-values/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0125c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(boston_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57bbfbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZILLOW_MEDIAN_PRICE = 739.18 # Price to April 2022\n",
    "\n",
    "SCALE_FACTOR=ZILLOW_MEDIAN_PRICE/np.median(boston_dataset.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74e16653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dollar_estimate(rm, ptratio,chas=False,large_range=True):\n",
    "    \"\"\"Estimate the price of a property in Boston.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    rm -- number of rooms in the property\n",
    "    ptratio -- number of students per teacher in the classroom for the school in the area\n",
    "    chas -- True if the property is next to the river, False otherwise\n",
    "    large_range -- True for 95% prediction interval, False for 68% interval\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if rm<1 or ptratio<1 or ptratio>50:\n",
    "        return 'That is unrealistic. Try again'\n",
    "    \n",
    "    \n",
    "    \n",
    "    log_est,upper,lower,conf = get_log_estimate(nr_rooms=rm,\n",
    "                                                students_per_classroom=ptratio, \n",
    "                                                next_to_river=chas,\n",
    "                                                high_confidence=large_range )\n",
    "\n",
    "    # Converto to today's dollars \n",
    "    dollar_est=np.e**log_est*1000*SCALE_FACTOR\n",
    "    upper_bound_prices=np.e**upper*1000*SCALE_FACTOR\n",
    "    lower_bound_prices=np.e**lower*1000*SCALE_FACTOR\n",
    "\n",
    "    # Round the dollar values to nearest thousand\n",
    "\n",
    "    round_est=np.around(dollar_est,-3)\n",
    "    round_upper=np.around(upper_bound_prices,-3)\n",
    "    round_lower=np.around(lower_bound_prices,-3)\n",
    "\n",
    "    print(f'The estimated property value is: {round_est}')\n",
    "    print(f'At {conf}% confidence the valuation range is:')\n",
    "    print(f'USD {round_lower} at the lower end to USD {round_upper} at the high end.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c9d98",
   "metadata": {},
   "source": [
    "Now, let's test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b60d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated property value is: 617000.0\n",
      "At 95% confidence the valuation range is:\n",
      "USD 424000.0 at the lower end to USD 898000.0 at the high end.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanemena/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_dollar_estimate(rm=2,ptratio=15,chas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e9d49",
   "metadata": {},
   "source": [
    "### Importing boston_valuation module "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d17499",
   "metadata": {},
   "source": [
    "Our last step is to create a python module with everything we developed above to be able to import it and calculate the house prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c918e7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated property value is: 562000.0\n",
      "At 95% confidence the valuation range is:\n",
      "USD 386000.0 at the lower end to USD 818000.0 at the high end.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanemena/.local/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import boston_valuation as val\n",
    "\n",
    "val.get_dollar_estimate(rm=4,ptratio=16,chas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f0809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
